# Artificial Intelligence and Machine Learning 

![image](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/blob/3425bbf68db6a703ee7e1151d535a12517a066b5/assets/Credit-Card%20fraud%20detection%20(2).png)



## ðŸŒŸ Support and Contribute this repository

If you like this project, feel free to **star**, **fork**, or check out the **contributors**:




[![Stars](https://img.shields.io/github/stars/mmahesh09/Artificial-Intelligence-and-Machine-Learning?style=social&t=12345)](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/stargazers)
&nbsp;&nbsp;&nbsp;
[![Forks](https://img.shields.io/github/forks/mmahesh09/Artificial-Intelligence-and-Machine-Learning?style=social&t=12345)](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/network/members)
&nbsp;&nbsp;&nbsp;
[![Contributors](https://img.shields.io/github/contributors/mmahesh09/Artificial-Intelligence-and-Machine-Learning?style=flat-square&t=12345)](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/graphs/contributors)
&nbsp;&nbsp;&nbsp;
[![Watchers](https://img.shields.io/github/watchers/mmahesh09/Artificial-Intelligence-and-Machine-Learning?style=social&t=12345)](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/watchers)
&nbsp;&nbsp;&nbsp;



 ## Flow chart 
![image](https://github.com/user-attachments/assets/bf3516c7-8b9e-4acd-8222-3f32361ff560)

## Index

* What is Artificial Intelligence?
* History
* Types of AI
* Terminologies of Artificial Intelligence
* Core concepts of Artificial Intelligence

## What is Artificial Intelligence 

Artificial Intelligence (AI) is the simulation of human intelligence in machines designed to think, learn, and perform tasks typically requiring human cognitive abilities. AI encompasses various techniques and technologies, enabling machines to perceive their environment, make decisions, solve problems, and adapt to new situations.




## History

| **Year** | **Event**                                                                                             | **Description**                                                                                      |
|----------|-------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|
| 1950     | **Turing Test**                                                                                       | Alan Turing proposes the concept of the Turing Test to assess a machine's ability to exhibit intelligent behavior. |
| 1956     | **Dartmouth Conference**                                                                               | The term "Artificial Intelligence" is coined during the Dartmouth Summer Research Project on AI, led by John McCarthy. |
| 1957     | **Perceptron**                                                                                        | Frank Rosenblatt develops the perceptron, an early neural network algorithm.                          |
| 1960s    | **Symbolic AI / Expert Systems**                                                                      | Research focuses on symbolic reasoning and expert systems, which mimic human decision-making.        |
| 1966     | **ELIZA**                                                                                             | Joseph Weizenbaum creates ELIZA, an early natural language processing program that simulates conversation. |
| 1970s    | **AI Winter**                                                                                         | A period of reduced funding and interest in AI due to unmet expectations and technical challenges.    |
| 1980     | **Rise of Expert Systems**                                                                            | Expert systems become popular in industries like healthcare and finance for decision-making tasks.    |
| 1986     | **Backpropagation Algorithm**                                                                          | Geoffrey Hinton, David Rumelhart, and Ronald Williams develop the backpropagation algorithm, reviving neural networks. |
| 1997     | **Deep Blue Defeats Garry Kasparov**                                                                   | IBM's Deep Blue defeats world chess champion Garry Kasparov, marking a milestone in AI capabilities.   |
| 2000s    | **Machine Learning Boom**                                                                              | Machine learning, especially statistical methods, gains traction with advancements in computing power. |
| 2006     | **Deep Learning**                                                                                     | Geoffrey Hinton and others popularize deep learning, a subset of machine learning using large neural networks. |
| 2012     | **AlexNet and ImageNet**                                                                               | AlexNet, a deep neural network, wins the ImageNet competition, significantly advancing computer vision. |
| 2014     | **Generative Adversarial Networks (GANs)**                                                            | Ian Goodfellow proposes GANs, enabling machines to generate realistic data (images, videos, etc.).     |
| 2016     | **AlphaGo Defeats Lee Sedol**                                                                          | Google's AI, AlphaGo, defeats world champion Go player Lee Sedol, showcasing AI's ability to master complex games. |
| 2018     | **BERT for NLP**                                                                                      | Google introduces BERT (Bidirectional Encoder Representations from Transformers), revolutionizing natural language understanding. |
| 2020s    | **AI in Real-World Applications**                                                                     | AI becomes widely adopted in various industries, including healthcare, finance, transportation, and entertainment. |
| 2023     | **GPT-4 Released**                                                                                   | OpenAI releases GPT-4, a powerful multimodal AI model that can handle text and images, pushing the limits of NLP. |





# Types of Artificial Intelligence

| **Type of AI**                | **Description**                               | **Example(s)**                                |
|-------------------------------|-----------------------------------------------|-----------------------------------------------|
| **Narrow AI (Weak AI)**        | Task-specific, limited capabilities           | Siri, Alexa, recommendation systems          |
| **General AI (AGI)**           | Human-like intelligence, wide-ranging tasks  | Still theoretical, under research            |
| **Superintelligent AI**        | Intelligence surpassing human abilities       | Still theoretical, under research            |
| **Reactive Machines**          | Reacts to stimuli, no memory                 | Deep Blue (chess), basic autonomous cars     |
| **Limited Memory AI**          | Uses past data to improve decisions          | Self-driving cars, recommendation systems    |
| **Theory of Mind AI**          | Understands emotions and intentions           | Experimental robots (e.g., Sophia)           |
| **Self-Aware AI**              | Has consciousness, independent thought        | Currently hypothetical                       |
| **Expert Systems**             | Mimics human experts' decision-making        | MYCIN, XCON                                  |
| **Natural Language Processing**| Processes and generates human language       | GPT-3, Google Translate, Siri               |
| **Computer Vision**            | Interprets and analyzes visual data           | Facial recognition, medical imaging          |
| **Robotics**                   | Physical robots performing tasks             | Drones, industrial robots, surgical robots   |





# Terminologies of Artificial Intelligence

| **Term**                        | **Description**                                                                                                                                           |
|----------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Artificial Intelligence (AI)** | The simulation of human intelligence in machines that can perform tasks like reasoning, learning, and problem-solving.                                     |
| **Machine Learning (ML)**        | A subset of AI that enables systems to learn from data and improve performance over time without explicit programming.                                        |
| **Deep Learning**                | A subset of ML that uses neural networks with many layers to analyze large amounts of data and make decisions.                                               |
| **Neural Networks**              | Computing systems inspired by the human brain's structure, consisting of interconnected nodes (neurons) that process information.                           |
| **Supervised Learning**          | A type of machine learning where the model is trained on labeled data, with input-output pairs used to learn the relationship.                              |
| **Unsupervised Learning**        | A type of machine learning where the model is trained on unlabeled data, and it must find hidden patterns or structures.                                   |
| **Reinforcement Learning**       | A type of machine learning where agents learn by interacting with an environment and receiving feedback (rewards or penalties).                             |
| **Natural Language Processing (NLP)** | A field of AI that focuses on the interaction between computers and human language, enabling tasks like translation, sentiment analysis, and chatbots.   |
| **Computer Vision**              | A field of AI that enables machines to interpret and process visual information from the world, such as images and videos.                                |
| **Generative Adversarial Networks (GANs)** | A class of neural networks where two networks (generator and discriminator) compete, enabling the creation of realistic synthetic data (images, videos). |
| **Algorithm**                    | A step-by-step procedure or formula for solving a problem, often used in AI systems to process data and make decisions.                                      |
| **Model**                        | A mathematical representation of a system or process that is used by an AI system to make predictions or decisions based on data.                           |
| **Feature Extraction**           | The process of transforming raw data into a set of characteristics (features) that a machine learning model can process and analyze.                        |
| **Training Data**                | A dataset used to train a machine learning model, containing input-output pairs or examples for the model to learn from.                                    |
| **Testing Data**                 | A dataset used to evaluate the performance of a trained machine learning model, often separate from the training data.                                       |
| **Overfitting**                  | A situation where a machine learning model learns the details and noise in the training data to the extent that it negatively affects its performance on new data. |
| **Underfitting**                 | A situation where a machine learning model is too simple to capture the underlying patterns in the data, resulting in poor performance.                    |
| **Bias**                         | A systematic error introduced into a machine learning model due to skewed or incomplete training data, leading to unfair or inaccurate predictions.         |
| **Inference**                    | The process of using a trained model to make predictions or decisions based on new, unseen data.                                                            |
| **Transfer Learning**            | A machine learning technique where a model trained on one task is adapted and fine-tuned to work on a different, but related, task.                        |
| **Recurrent Neural Networks (RNNs)** | A type of neural network where connections between nodes can form cycles, allowing the network to process sequences of data (e.g., time-series or text).   |
| **Convolutional Neural Networks (CNNs)** | A type of neural network specialized in processing grid-like data, such as images, by using convolutional layers to detect patterns.                        |
| **Autonomous Systems**           | Machines or robots capable of performing tasks or making decisions independently without human intervention, often powered by AI.                           |
| **Chatbots**                     | AI-powered systems designed to simulate conversation with users, typically through text or voice.                                                          |
| **Speech Recognition**           | The AI technology that allows machines to understand and interpret human speech, enabling voice commands and interactions.                                 |
| **Computer Vision**              | The field of AI focuses on enabling machines to interpret and analyze visual data from the world, like images and videos.                                    |
| **AI Ethics**                     | The study of the moral and societal implications of AI technologies, addressing concerns like privacy, bias, accountability, and job displacement.           |
| **Human-Computer Interaction (HCI)** | The study of how people interact with computers and AI systems, with an emphasis on usability and improving user experience.                                   |
| **Swarm Intelligence**           | A type of artificial intelligence based on the collective behavior of decentralized systems, such as in the behavior of ants, bees, or drones.              |
| **Artificial General Intelligence (AGI)** | A type of AI that aims to replicate human-level cognitive abilities and can perform a wide range of tasks across different domains.                         |
| **Artificial Narrow Intelligence (ANI)** | AI systems designed to perform specific tasks with high proficiency, but lacking general cognitive abilities.                                                |
| **Ethical AI**                   | The creation of AI systems that align with ethical principles, ensuring fairness, transparency, accountability, and respect for human rights.               |



# Core concepts of Artificial Intelligence
![WhatsApp Image 2025-01-02 at 01 33 52_9cc1ed23](https://github.com/user-attachments/assets/467c8ab1-bedb-4c13-845e-a3db345d769c)



# Machine Learning 
![image](https://github.com/mmahesh09/Artificial-Intelligence-and-Machine-Learning/blob/9f49da32cfc3b1d7e699dce890c60e691a4c1401/Machine%20Learning/images/Credit-Card%20fraud%20detection%20(4).png)

## Index
* Prerequisites of Machine Learning
* What is Machine Learning?
* Why Machine Learning
* Types of Machine Learning
* Terminologies of Machine Learning
* Applications of Machine Learning

  ## Prerequisites for Machine Learning

| **Prerequisite**       | **Description**                                                                                   | **Recommended YouTube Video**                                                                                   |
|------------------------|---------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------|
| **Linear Algebra**     | Understanding vectors, matrices, and operations involving them is crucial for algorithms and data representation in machine learning. | [Link](https://youtu.be/rSjt1E9WHaQ?si=X-t1j5GXb7wj9ls-)                                    |
| **Calculus**           | Grasping derivatives and integrals aids in understanding optimization algorithms used in training models. | [Link](https://youtube.com/playlist?list=PLRDl2inPrWQVu2OvnTvtkRpJ-wz-URMJx&si=3lV92cuxrDRoigbn)                                    |
| **Probability & Statistics** | Knowledge of probability distributions, statistical tests, and data analysis is essential for making inferences and predictions. | [Link](https://www.geeksforgeeks.org/statistics-for-machine-learning/)                                    |
| **Programming Skills** | Proficiency in programming languages, particularly Python, is necessary for implementing algorithms and handling data. | [Link](https://youtu.be/qwAFL1597eM?si=5jroV5AdBkVfPXc9)                                    |
| **Data Structures & Algorithms** | Understanding data organization and algorithmic problem-solving enhances efficiency in model implementation. | [Link](https://youtu.be/f9Aje_cN_CY?si=lKhTYiW1l-82NY8p)                                    |
| **Domain Knowledge**   | Familiarity with the specific field of application helps in selecting appropriate models and interpreting results effectively. | [Link](https://youtube.com/playlist?list=PLLy_2iUCG87D1CXFxE-SxCFZUiJzQ3IvE&si=Ws5D9txm1ktqZuFf)                                    |
                                  


# Machine Learning
Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on developing systems capable of learning and improving from experience without being explicitly programmed. ML algorithms use data to identify patterns, make predictions, or make decisions, adapting their performance as they are exposed to more data.

# Why Machine Learning?

Machine learning is crucial because it enables systems to automatically learn and improve from data, making them more adaptable, efficient, and intelligent over time. It drives innovation by solving complex problems across industries like healthcare (disease detection), finance (fraud detection), and technology (personalized recommendations). Unlike traditional programming, ML excels in tasks where explicit rules are hard to define, such as image recognition, language translation, and predictive analytics. With the explosion of big data, ML transforms vast information into actionable insights, enhancing decision-making and automating repetitive tasks. Its ability to uncover hidden patterns makes it a cornerstone of modern AI advancements.

# Types of Machine Learning

* Supervised Learning
* Unsupervised Learning
* Reinforcement Learning
---
  ### 1. **Supervised Learning**  
Supervised learning involves training a model on labeled data, where inputs have corresponding outputs. The algorithm learns to map inputs to the correct outputs and generalize to unseen data. Tasks include classification (categorizing data) and regression (predicting continuous values).  
**Examples**:  
- **Classification**: Email spam detection (spam or not spam).  
- **Regression**: Predicting house prices based on features like size and location.  
Common algorithms include Decision Trees, Support Vector Machines, and Neural Networks.

---

### 2. **Unsupervised Learning**  
Unsupervised learning works on unlabeled data to identify patterns, groupings, or structures. Itâ€™s used when no explicit output is provided, often for clustering or dimensionality reduction.  
**Examples**:  
- **Clustering**: Customer segmentation in marketing (grouping customers by behavior).  
- **Dimensionality Reduction**: Reducing features in large datasets, like PCA for image compression.  
Key algorithms include K-Means, Hierarchical Clustering, and Autoencoders.

---

### 3. **Reinforcement Learning**  
Reinforcement learning focuses on training an agent to make decisions in an environment by maximizing cumulative rewards through trial and error. The agent learns from feedback (rewards or penalties).  
**Examples**:  
- Training robots to walk.  
- Optimizing strategies in games like chess or Go.  
Popular algorithms include Q-Learning, Deep Q-Networks (DQN), and Policy Gradient Methods.  

## Machine Learning Terminologies

| **Term**               | **Definition**                                                                                   | **Example**                                                                                       |
|-------------------------|-----------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------|
| **Dataset**            | A collection of data used for training, testing, and validating machine learning models.        | A CSV file containing features like age, income, and labels like "yes/no" for loan approval.      |
| **Feature**            | An individual measurable property or characteristic of the data.                               | Age, income, and education level in a dataset predicting loan approval.                           |
| **Label**              | The target variable that the model aims to predict or classify.                                | "Spam" or "Not Spam" in an email classification problem.                                          |
| **Model**              | A mathematical representation of the relationships in the data learned by an algorithm.        | A neural network trained to identify handwritten digits.                                          |
| **Training**           | The process of teaching a model using labeled data to find patterns and relationships.         | Feeding images of cats and dogs with labels to train a classifier.                                |
| **Testing**            | Evaluating the model's performance on unseen data to check its generalization.                 | Using a separate dataset to assess a trained fraud detection model.                               |
| **Overfitting**        | When a model learns the training data too well, including noise, and fails to generalize.       | A decision tree that perfectly fits training data but performs poorly on new data.                |
| **Underfitting**       | When a model is too simple to capture the underlying patterns in the data.                     | A linear regression model failing to fit a quadratic relationship in the data.                   |
| **Hyperparameters**    | External parameters set before training to control the learning process.                       | Learning rate, number of layers in a neural network, or K in K-Means clustering.                  |
| **Epoch**              | One complete pass through the entire training dataset.                                         | Training a neural network for 10 epochs.                                                         |
| **Learning Rate**      | A hyperparameter controlling how much the model adjusts weights during training.               | A lower learning rate may result in slower but more stable convergence.                           |
| **Loss Function**      | A function measuring the difference between predicted and actual outputs.                      | Mean Squared Error (MSE) for regression tasks or Cross-Entropy for classification.                |
| **Regularization**     | Techniques to prevent overfitting by adding constraints or penalties to the model.             | L1 or L2 regularization to limit model complexity.                                                |
| **Gradient Descent**   | An optimization algorithm to minimize the loss function by updating model weights.             | Stochastic Gradient Descent (SGD) for deep learning models.                                       |
| **Supervised Learning**| Learning with labeled data to predict outcomes.                                                | Predicting housing prices using historical data.                                                  |
| **Unsupervised Learning**| Learning patterns or structures in unlabeled data.                                           | Clustering customers into groups based on purchasing behavior.                                    |
| **Reinforcement Learning**| Learning to make decisions through rewards and penalties.                                   | Training a robot to navigate a maze by maximizing its rewards.                                    |
| **Confusion Matrix**   | A table summarizing a classification model's predictions against true labels.                  | True Positives (TP), False Positives (FP), True Negatives (TN), False Negatives (FN).             |
| **Accuracy**           | The ratio of correct predictions to the total predictions made by the model.                   | (TP + TN) / Total Predictions.                                                                    |
| **Precision**          | The ratio of true positives to all predicted positives.                                        | TP / (TP + FP).                                                                                   |
| **Recall**             | The ratio of true positives to all actual positives.                                           | TP / (TP + FN).                                                                                   |
| **F1 Score**           | The harmonic mean of precision and recall.                                                    | 2 * (Precision * Recall) / (Precision + Recall).                                                  |

# Courses

| Course Title                                                                                   | Platform | Instructor(s)            | Description                                                                                                                | Link                                                                                   |
|------------------------------------------------------------------------------------------------|----------|--------------------------|----------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------|
| Machine Learning                                                                               | Coursera | Andrew Ng                | A comprehensive introduction to machine learning, covering supervised and unsupervised learning, best practices, and more. | [Course Link](https://www.coursera.org/learn/machine-learning)                         |
| Deep Learning Specialization                                                                   | Coursera | Andrew Ng                | A five-course specialization focusing on deep learning, including neural networks, optimization, and more.                 | [Specialization Link](https://www.coursera.org/specializations/deep-learning)          |
| Machine Learning A-Zâ„¢: Hands-On Python & R In Data Science                                     | Udemy    | Kirill Eremenko, Hadelin de Ponteves | A practical course covering machine learning algorithms in Python and R, with real-world examples.                        | [Course Link](https://www.udemy.com/course/machinelearning/)                           |
| Python for Data Science and Machine Learning Bootcamp                                          | Udemy    | Jose Portilla            | An extensive bootcamp covering Python programming, data analysis, visualization, and machine learning.                    | [Course Link](https://www.udemy.com/course/python-for-data-science-and-machine-learning-bootcamp/) |
| Machine Learning with Python                                                                   | Coursera | IBM                      | A beginner-friendly course introducing machine learning using Python, covering various algorithms and techniques.          | [Course Link](https://www.coursera.org/learn/machine-learning-with-python)             |
| Advanced Machine Learning Specialization                                                       | Coursera | National Research University Higher School of Economics | An advanced series covering deep learning, reinforcement learning, natural language processing, and more. | [Specialization Link](https://www.coursera.org/specializations/aml)                    |
| Machine Learning Crash Course                                                                  | Google AI| Google                   | A fast-paced, practical introduction to machine learning with TensorFlow APIs, including interactive visualizations.       | [Course Link](https://developers.google.com/machine-learning/crash-course)             |
| Introduction to Machine Learning for Coders                                                    | Fast.ai  | Jeremy Howard            | A hands-on course teaching machine learning with a focus on coding and practical implementation using Python.              | [Course Link](https://course.fast.ai/)                                                 |
| Machine Learning Engineering for Production (MLOps) Specialization                             | Coursera | Andrew Ng, DeepLearning.AI | Focuses on the deployment and production of machine learning models, covering MLOps concepts and best practices.           | [Specialization Link](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops) |
| Data Science and Machine Learning Bootcamp with R                                              | Udemy    | Jose Portilla            | A comprehensive course covering data science and machine learning concepts using the R programming language.               | [Course Link](https://www.udemy.com/course/data-science-and-machine-learning-bootcamp-with-r/) |


  
# ML




